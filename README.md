# Anime Data Warehouse & Analytics Platform

An end-to-end **Data Engineering project** that ingests anime ranking data from RapidAPI, processes semiâ€‘structured JSON in Snowflake, transforms data using dbt, models a dimensional warehouse using Snowflake Stored Procedures, and visualizes insights in Power BI.

This project demonstrates realâ€‘world ELT architecture, CI/CDâ€‘style deployments, and productionâ€‘grade warehouse design.

---

## ğŸš€ Architecture Overview

```
RapidAPI (anime-db)
        |
        v
Python Ingestion (API â†’ JSON)
        |
        v
Snowflake RAW layer (VARIANT)
        |
        v
STAGING layer (dbt transformations)
        |
        v
MART layer (Facts & Dimensions via Snowflake Stored Procedures)
        |
        v
Power BI Dashboards
```

Deployment flow:

```
Local SQL â†’ GitHub â†’ Workflow â†’ Snowflake
```

---

## ğŸ§± Data Warehouse Layers

### RAW

* Stores full API JSON response in `VARIANT`
* Batch tracking using `ingest_id` and `fetched_at`

### STAGING (dbt)

* Flattens JSON
* Normalizes genre arrays
* Tables:

  * `STG_ANIME`
  * `STG_ANIME_GENRES`

### MART (Analytics Layer)

Dimensional star schema built using Snowflake SQL Stored Procedures:

**Dimensions**

* `DIM_ANIME`
* `DIM_GENRE`

**Fact**

* `FACT_ANIME_RANKINGS`

---

## ğŸ›  Tech Stack

| Layer           | Technology                          |
| --------------- | ----------------------------------- |
| API Source      | RapidAPI (anime-db)                 |
| Ingestion       | Python, Requests                    |
| Data Warehouse  | Snowflake                           |
| Transformations | dbt Cloud                           |
| Modeling        | Snowflake SQL Stored Procedures     |
| Orchestration   | Stored Procedure Pipeline           |
| BI              | Power BI                            |
| Version Control | GitHub                              |
| CI/CD           | Workflowâ€‘based Snowflake deployment |

---

## ğŸ“¦ Data Sources

### Primary

* RapidAPI â€“ Anime DB endpoint

Fields used:

* id
* episodes
* ranking
* status
* type
* synopsis
* genres (array)

### Future extensions

* Jikan API (metadata & popularity)
* Static CSV datasets

---

## ğŸ“ Warehouse Schema

### DIM_ANIME

| Column         |
| -------------- |
| anime_key (PK) |
| anime_id       |
| episodes       |
| status         |
| type           |
| synopsis       |
| created_at     |
| updated_at     |

### DIM_GENRE

| Column         |
| -------------- |
| genre_key (PK) |
| genre_name     |
| created_at     |

### FACT_ANIME_RANKINGS

| Column         |
| -------------- |
| anime_key (FK) |
| ranking        |
| snapshot_ts    |
| ingest_id      |
| created_at     |

---

## âš™ï¸ Stored Procedures

| Procedure                     | Purpose                        |
| ----------------------------- | ------------------------------ |
| `SP_LOAD_DIM_ANIME`           | Loads/updates anime dimension  |
| `SP_LOAD_DIM_GENRE`           | Loads genre dimension          |
| `SP_LOAD_FACT_ANIME_RANKINGS` | Inserts ranking snapshots      |
| `SP_RUN_MART_PIPELINE`        | Orchestrates full MART refresh |

Run full pipeline:

```sql
CALL MART.SP_RUN_MART_PIPELINE();
```

---

## ğŸ“Š Power BI Dashboards

Features:

* Total anime count
* Average & best ranking KPIs
* Top 10 anime by ranking
* Ranking trends over time
* Status & type distribution

Star schema modeling used for performance & scalability.

---

## ğŸ—‚ Project Structure

```
anime-data-analytics/
â”‚
â”œâ”€â”€ ingestion/
â”‚   â””â”€â”€ rapidapi/
â”‚       â””â”€â”€ rapidapi_anime_ingest.py
â”‚
â”œâ”€â”€ snowflake/
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ database & schema setup
â”‚       â”œâ”€â”€ RAW table creation
â”‚       â”œâ”€â”€ MART table creation
â”‚       â”œâ”€â”€ stored procedures
â”‚
â”œâ”€â”€ dbt/
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ sources/
â”‚       â”œâ”€â”€ staging/
â”‚       â””â”€â”€ marts/
â”‚
â”œâ”€â”€ powerbi/
â”‚   â””â”€â”€ anime_dashboard.pbix
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ .env (ignored)
â”‚
â””â”€â”€ README.md
```

---

## â–¶ï¸ How to Run

### 1. Environment variables

Create `config/.env`:

```
RAPIDAPI_KEY=...
SNOWFLAKE_USER=...
SNOWFLAKE_PASSWORD=...
SNOWFLAKE_ACCOUNT=...
```

### 2. Run ingestion

```bash
python ingestion/rapidapi/rapidapi_anime_ingest.py
```

### 3. Run dbt

```bash
dbt run
dbt test
```

### 4. Run warehouse pipeline

```sql
CALL MART.SP_RUN_MART_PIPELINE();
```

### 5. Open Power BI

Load tables from:

```
ANIME_DWH.MART
```

---

## ğŸ§ª Key Engineering Concepts Demonstrated

* API pagination & batching
* Semiâ€‘structured JSON ingestion
* ELT architecture
* dbt transformations
* Dimensional modeling (Star Schema)
* SCD Typeâ€‘1 dimensions
* Incremental fact loading
* Warehouseâ€‘side orchestration
* CI/CD for Snowflake SQL
* BI modeling

---

## ğŸ“ˆ Resume Highlights

* Built an APIâ€‘driven ELT pipeline using Snowflake, dbt Cloud, Python, and Power BI
* Designed RAW â†’ STAGING â†’ MART architecture with semiâ€‘structured JSON handling
* Implemented dimensional modeling with Snowflake SQL stored procedures
* Developed orchestration procedure to automate warehouse refresh
* Created analytical dashboards for ranking trend analysis

---

## ğŸ”® Future Enhancements

* Integrate Jikan API for popularity & studio metadata
* Add static datasets for ratings history
* Implement SCD Typeâ€‘2 for dimensions
* Add task scheduling in Snowflake
* Deploy dashboards to Power BI Service

---

## ğŸ‘¤ Author

Tushar Negi
Data Engineer (ETL â†’ Data Engineering Transition Project)

---

â­ If you found this project useful, consider starring the repository!
